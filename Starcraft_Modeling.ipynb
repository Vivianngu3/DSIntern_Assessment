{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbb0b21",
   "metadata": {},
   "source": [
    "# 1. DEFINING THE PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65debdc",
   "metadata": {},
   "source": [
    "You’re given a dataset of Starcraft player performance data in ranked games. We want to develop a model to predict a player’s rank using the information provided in the dataset.\n",
    "\n",
    "**Language:** Python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a8c7f",
   "metadata": {},
   "source": [
    "# 2. LOAD, EXPLORE, CLEAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e271c3",
   "metadata": {},
   "source": [
    "## LOAD CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"starcraft_player_data.csv\") \n",
    "#check first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ccf253",
   "metadata": {},
   "source": [
    "## EXPLORE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ea72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking general information about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fa4c7",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "1. 3,395 rows and 20 columns\n",
    "2. LeagueIndex represents the players rank\n",
    "3. Data Types: Age, HoursPerWeek, and TotalHours are strings but these categories should be numeric, if its not changed there can be hidden issues in the analysis.\n",
    "5. Non-Null Count shows there is no missing values but this would need to be further inspected because of the previous point.\n",
    "6. Columns that show gameplay statistics and could be potential features: APM, MinimapAttacks, WorkersMade, ComplexUnitsMade.\n",
    "\n",
    "**To-Do:**\n",
    "Data cleaning time!\n",
    "1. Convert the object types into numeric\n",
    "2. Check for any duplicates \n",
    "3. Explore more for any missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec7153",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a08fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dtype from object to numeric\n",
    "df[['Age', 'HoursPerWeek', 'TotalHours']] = df[['Age', 'HoursPerWeek', 'TotalHours']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "\n",
    "# Drop duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirming changes\n",
    "df.info(), f\"Number of duplicates removed: {duplicate_count}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d0854",
   "metadata": {},
   "source": [
    "## HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run to check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9d350",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "Since this is low amount that is missing, I can either replace these values with the mean or deletion. I will inspect it a bit further to understand the type of missing values. I do not want to discard any data that could affect the conclusion or cause biases if it is not randomly distributed.\n",
    "\n",
    "**To-Do:**\n",
    "1. Create visualization for distribution of missing values\n",
    "2. Determine how to handle it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce686ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "#missing data visualization\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9556df3",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "1. By using this matrix chart I am able to see that the missing data is MAR\n",
    "2. Since few rows have missing data we can just impute it using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb83cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with column mean\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Check for nulls after cleaning\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620ac63",
   "metadata": {},
   "source": [
    "# 3. EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb0b83",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats of updated dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccb56e",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "1. LeagueIndex ranges from 1-8, making this a cateforical ranking system\n",
    "2. Age is between 16 to 44 (median:21)\n",
    "3. HoursPerWeek has a big variety, meaning there is possible outliers\n",
    "4. Total hours also has a big range meaning there are existing outliers, also 1,000,000 is an impossible number\n",
    "5. APM range is 22 to 389 and can indicate that highly skilled players act faster\n",
    "6. SelectBy and AssignTo Hotkeys have very small values and could need rescaling \n",
    "7. Other columns with low average can check for importance to ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7331331",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ec7ee",
   "metadata": {},
   "source": [
    "### Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1c1e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot histograms for feature distributions\n",
    "df.hist(figsize=(15, 12), bins=30, edgecolor='black')\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ff678",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "1. **Skewed Distributions:** TotalHours and HoursPerWeek are heavily right-skewed, indicating extreme values. APM has a right skew, suggesting some players perform many more actions than others.\n",
    "\n",
    "2. **Normally Distributed Features:** Age appears roughly normal, centered around early 20s. LeagueIndex has a slight central tendency, suggesting more mid-tier players.\n",
    "\n",
    "3. **Sparse Features:** Columns dealing with Minimap and hotkey usage have very small values and might require scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871a1d3",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4547e5",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "1. **Strongest Correlations with LeagueIndex:** APM: More actions per minute correlate with higher ranks. MinimapAttacks: Frequent minimap use is linked to better players. TotalMapExplored: More exploration correlates with higher rank. AssignToHotkeys: Using hotkeys is associated with skill.\n",
    "\n",
    "2. **Weak or No Correlation with LeagueIndex:** Game ID has no effect on rank.  HoursPerWeek & TotalHours: Time spent playing is not a strong predictor.\n",
    "\n",
    "3. **Multicollinearity Risks:** APM, ActionsInPAC, and ActionLatency are highly correlated—we would need to remove redundant features. ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9062b",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate boxplots for key features to detect outliers\n",
    "key_features = [\"APM\", \"TotalHours\", \"HoursPerWeek\", \"MinimapAttacks\", \"TotalMapExplored\"]\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, feature in enumerate(key_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(y=df[feature])\n",
    "    plt.title(f\"Boxplot of {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a6607",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "1. **Extreme Outliers:** As mentioned before, some players in **TotalHours** have over 1,000,000 total hours, which is unrealistic. **HoursPerWeek** has extreme values up to 168 hours/week (unrealistic 24/7 playtime).\n",
    "\n",
    "2. APM (Actions Per Minute): Some players have extremely high APM (>350), which may be valid but should be examined.\n",
    "\n",
    "3. MinimapAttacks & TotalMapExplored: Outliers are present but less extreme than playtime features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730e555",
   "metadata": {},
   "source": [
    "### Outlier Handling\n",
    "Based on the findings I will be dealing with the outliers by percentile capping (trimming values beyond the 99th percentile. \n",
    "These outliers seem mostly due to entry mistakes.\n",
    "This would modify extreme values by replacing them with predefined threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c396e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define capping function (99th percentile)\n",
    "def cap_outliers(df, columns, percentile=0.99):\n",
    "    for col in columns:\n",
    "        upper_limit = df[col].quantile(percentile)\n",
    "        df[col] = df[col].clip(upper=upper_limit)\n",
    "    return df\n",
    "\n",
    "# Apply capping to selected features\n",
    "outlier_columns = [\"TotalHours\", \"HoursPerWeek\", \"APM\", \"MinimapAttacks\", \"TotalMapExplored\"]\n",
    "df = cap_outliers(df, outlier_columns)\n",
    "\n",
    "# Verify changes with new boxplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(outlier_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(y= df[feature])\n",
    "    plt.title(f\"Boxplot of {feature} (Capped)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa680a",
   "metadata": {},
   "source": [
    "# 4. MODEL SELECTION & TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1343bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for model training and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46516de",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Compute Variance Inflation Factor (VIF)\n",
    "X_selected = df.drop(columns=['LeagueIndex'])  # Exclude target variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_selected.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_selected.values, i) for i in range(len(X_selected.columns))]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0429d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the correlations to the Target\n",
    "correlations = df.corr()['LeagueIndex'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features based on correlation and relevance\n",
    "selected_features = [\n",
    "    \"APM\", \"GapBetweenPACs\", \"AssignToHotkeys\", \"ActionLatency\", \"MinimapAttacks\", \"SelectByHotkeys\", \"TotalHours\"\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = \"LeagueIndex\"\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[selected_features]  # Features\n",
    "y = df[target]  # Target\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Confirm data shape\n",
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f712b8",
   "metadata": {},
   "source": [
    "## Cross Validation on Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad043e",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "# Creating dataframe for classification report for better readability\n",
    "report_df = pd.DataFrame(classification_rep).transpose()\n",
    "print(report_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae0e34",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "# Creating dataframe for classification report for better readability\n",
    "report_rf_df = pd.DataFrame(classification_rep_rf).transpose()\n",
    "print(report_rf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c6ee4",
   "metadata": {},
   "source": [
    "## Building Classification Model using Random Forest\n",
    "Although the scores were low, based on my findings and the problem question, I believe this model would be the best fit due to these factors:\n",
    "1. Handling complex relationships: There are multiple complex features and relationships to determine a players rank.\n",
    "2. Handling imbalanced classes: As shown before, there is a clear sample imbalance amongst LeagueIndex 7-8.\n",
    "3. Handling feature scale: As seen in the dataset there are some features with a much lower scale compared to others.\n",
    "4. Providing feature importance: This further helps with feature selection and understanding their relationship between ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d3841",
   "metadata": {},
   "source": [
    "## Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798dcb96",
   "metadata": {},
   "source": [
    "**To further improve the model:**\n",
    "1. Feature Selection to find the most important predictors.\n",
    "2. Balance the dataset (address rank imbalances).\n",
    "3. Try more models like Gradient Boosting Models (like XGBoost or LightGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419933fa",
   "metadata": {},
   "source": [
    "## Feature Selection prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on all features\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Convert to a Pandas DataFrame for easier analysis\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top N features (e.g., top 10)\n",
    "N = 10\n",
    "top_features = importance_df['Feature'].head(N).tolist()\n",
    "\n",
    "# Create a new dataset with only the selected features\n",
    "X_train_selected = X_train[top_features]\n",
    "X_test_selected = X_test[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5501393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model again with selected features\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred_selected = rf_selected.predict(X_test_selected)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_selected))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_selected))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f189297",
   "metadata": {},
   "source": [
    "## Address Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = X_train_selected  # Features\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Count instances in each rank\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new distribution\n",
    "print(\"After SMOTE:\", Counter(y_train_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab430b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on balanced data\n",
    "rf_model_smote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_smote.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_smote = rf_model_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80f380",
   "metadata": {},
   "source": [
    "### Model Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3def60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate results\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "\n",
    "report_improve_df = pd.DataFrame(classification_report(y_test, y_pred_smote, output_dict=True)).transpose()\n",
    "print(report_improve_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
